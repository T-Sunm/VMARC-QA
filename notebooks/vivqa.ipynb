{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737a5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Đây có phải là bức ảnh chụp nhiều độ phơi sáng của vận động viên trượt tuyết mặc áo đen không?', 'image': <PIL.Image.Image image mode=RGB size=640x480 at 0x746E4D711FC0>, 'image_path': '/mnt/VLAI_data/COCO_Images/val2014/COCO_val2014_000000393271.jpg', 'explanation': ['hình người mặc cùng một bộ quần áo khi trượt xuống dốc', 'có vẻ như là cùng một người trượt tuyết làm những pha nhào lộn khác nhau', 'cùng một người trượt tuyết xuất hiện nhiều lần'], 'answer': 'có', 'question_id': '393271001'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Đường dẫn\n",
    "json_path = \"/mnt/VLAI_data/ViVQA-X/ViVQA-X_val.json\"\n",
    "coco_img_dir = \"/mnt/VLAI_data/COCO_Images/val2014/\"\n",
    "\n",
    "# Đọc file JSON\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "samples = []\n",
    "for item in data:\n",
    "    img_path = os.path.join(coco_img_dir, item[\"image_name\"])\n",
    "    # Mở ảnh thành PIL Image\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    sample = {\n",
    "        \"question\": item[\"question\"],\n",
    "        \"image\": image,  # <-- PIL Image object\n",
    "        \"image_path\": img_path,\n",
    "        \"explanation\": item[\"explanation\"],  # list\n",
    "        \"answer\": item[\"answer\"],\n",
    "        \"question_id\": item[\"question_id\"]\n",
    "    }\n",
    "    samples.append(sample)\n",
    "\n",
    "# Kiểm tra 1 sample\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4e2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Processor' from 'processor' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Processor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Processor' from 'processor' (unknown location)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Thêm đường dẫn tới thư mục chứa processor.py\n",
    "# Đường dẫn này tương đối từ vị trí của notebook\n",
    "processor_path = os.path.abspath('../ViVQA/beit3/HCMUS')\n",
    "if processor_path not in sys.path:\n",
    "    sys.path.append(processor_path)\n",
    "\n",
    "from processor import Processor\n",
    "from PIL import Image\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\"ngocson2002/vivqa-model\", trust_remote_code=True).to(device)\n",
    "processor = Processor()\n",
    "\n",
    "image = Image.open(samples[0][\"image_path\"]).convert(\"RGB\")\n",
    "display(image)\n",
    "question = samples[0][\"question\"]\n",
    "\n",
    "inputs = processor(image, question, return_tensors='pt')\n",
    "inputs[\"image\"] = inputs[\"image\"].unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "    logits = output.logits\n",
    "    idx = logits.argmax(-1).item()\n",
    "\n",
    "print(\"Predicted answer:\", model.config.id2label[idx]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAK-Minh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
